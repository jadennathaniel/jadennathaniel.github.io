# GPT-4o Mini
OpenAI has introduced the GPT-4o mini, a small model designed to make AI more accessible and affordable for developers. The model offers superior performance at a fraction of the cost of previous models, including the regular GPT-4o. It scored 82% on the MMLU benchmark and outperformed GPT-4 on chat preferences in the LMSYS leaderboard. The model is priced at 15 cents per million input tokens and 60 cents per million output tokens, making it significantly more cost-effective than its predecessors. Key features include low cost and latency, a 128K token context window, up to 16K output tokens per request, a knowledge cutoff in October 2023, an improved tokeniser for efficient non-English text handling, and support for text and vision in the API.

GPT-4o mini outshines other small models across various benchmarks, including MMLU (textual intelligence) at 82.0%, MGSM (math reasoning) at 87.0%, HumanEval (coding performance) at 87.2%, and MMMU (multimodal reasoning) at 59.4%. Developers can leverage GPT-4o mini for a wide range of applications, including chaining or parallelizing multiple model calls, passing large volumes of context, and building real-time text response systems. OpenAI has prioritized safety in its development, implementing pre-training content filtering, post-training alignment, and an innovative "instruction hierarchy" method to resist jailbreaks and prompt injections.